#!/usr/local/bin/env python

#=============================================================================================
# MODULE DOCSTRING
#=============================================================================================

"""
repex
=====

Replica-exchange simulation algorithms and specific variants.

DESCRIPTION

This module provides a general facility for running replica-exchange simulations, as well as
derived classes for special cases such as parallel tempering (in which the states differ only
in temperature) and Hamiltonian exchange (in which the state differ only by potential function).

Provided classes include:

* ReplicaExchange - Base class for general replica-exchange simulations among specified ThermodynamicState objects
* ParallelTempering - Convenience subclass of ReplicaExchange for parallel tempering simulations (one System object, many temperatures/pressures)
* HamiltonianExchange - Convenience subclass of ReplicaExchange for Hamiltonian exchange simulations (many System objects, same temperature/pressure)

TODO

* Add analysis facility accessible by user.
* Give up on Context caching and revert to serial Context creation/destruction if we run out of GPU memory (issuing an alert).
* Store replica self-energies and/or -ln q(x) for simulation (for analyzing correlation times).
* Add analysis facility.
* Allow user to call initialize() externally and get the NetCDF file handle to add additional data?
* Store / restore parameters and System objects from NetCDF file for resuming and later analysis.
* Sampling support:
  * Short-term: Add support for user to specify a callback to create the Integrator to use ('integrator_factory' or 'integrator_callback').
  * Longer-term: Allow a more complex MCMC sampling scheme consisting of one or more moves to be specified through mcmc.py facility.
* Allow different choices of temperature handling during exchange attempts:
  * scale velocities (exchanging only on potential energies) - make this the default?
  * randomize velocities (exchanging only on potential energies)
  * exchange on total energies, preserving velocities (requires more replicas)
* Add control over number of times swaps are attempted when mixing replicas, or compute best guess automatically
* Add another layer of abstraction so that the base class uses generic log probabilities, rather than reduced potentials?
* Use interface-based checking of arguments so that different implementations of the OpenMM API (such as pyopenmm) can be used.
* Eliminate file closures in favor of syncs to avoid closing temporary files in the middle of a run.

COPYRIGHT

Written by John D. Chodera <jchodera@gmail.com> while at the University of California Berkeley.

LICENSE

This code is licensed under the latest available version of the MIT License.

"""

#=============================================================================================
# GLOBAL IMPORTS
#=============================================================================================

from simtk import openmm
from simtk import unit

import os
import math
import copy
import time
import inspect
import datetime
import logging
import importlib
import collections

import numpy as np
import mdtraj as md
import netCDF4 as netcdf

import openmmtools as mmtools
from openmmtools.states import ThermodynamicState

from yank import utils, mpi

logger = logging.getLogger(__name__)

#=============================================================================================
# MODULE CONSTANTS
#=============================================================================================

kB = unit.BOLTZMANN_CONSTANT_kB * unit.AVOGADRO_CONSTANT_NA # Boltzmann constant

# TODO: Fix MAX_SEED when we determine what maximum allowed seed is.
#MAX_SEED = 4294967 # maximum seed for OpenMM setRandomNumberSeed
MAX_SEED = 2**31 - 1 # maximum seed for OpenMM setRandomNumberSeed

#=============================================================================================
# Exceptions
#=============================================================================================

class ParameterException(Exception):
    """
    Exception denoting that an incorrect argument has been specified.

    """
    pass


# ==============================================================================
# REPLICA EXCHANGE REPORTER
# ==============================================================================

class Reporter(object):
    """Handle storage write/read operations and different format conventions.

    You can use this object to programmatically inspect the data generated by
    ReplicaExchange.

    Parameters
    ----------
    storage : str
        The path to the file. In the future this will be able to take Storage
        classes as well.
    mode : str
        The mode of the file between 'r', 'w', and 'a' (or equivalently 'r+').

    """
    def __init__(self, storage, mode='r'):
        # Open NetCDF 4 file for writing.
        ncfile = netcdf.Dataset(storage, mode, version='NETCDF4')

        # Create header if needed.
        if 'scalar' not in ncfile.dimensions:
            # Create common dimensions.
            ncfile.createDimension('scalar', 1)  # Scalar dimension.
            ncfile.createDimension('iteration', 0)  # Unlimited number of iterations.
            ncfile.createDimension('spatial', 3)  # Number of spatial dimensions.

            # Set global attributes.
            setattr(ncfile, 'application', 'YANK')
            setattr(ncfile, 'program', 'yank.py')
            setattr(ncfile, 'programVersion', 'unknown')  # TODO: Include actual version.
            setattr(ncfile, 'Conventions', 'YANK')
            setattr(ncfile, 'ConventionVersion', '0.1')

        # Save NetCDF file.
        self._ncfile = ncfile

    def __del__(self):
        """Synchronize and close the storage."""
        if self._ncfile is not None:
            # Don't sync if we don't have write access.
            if self._ncfile.isopen():
                self._ncfile.sync()
                self._ncfile.close()
            self._ncfile = None

    def sync(self):
        """Force any buffer to be flushed to the file."""
        self._ncfile.sync()

    @mmtools.utils.with_timer('Reading thermodynamic states from storage')
    def read_thermodynamic_states(self):
        """Retrieve the stored thermodynamic states.

        Returns
        -------
        thermodynamic_states : list of ThermodynamicStates
            The previously stored thermodynamic states. During the simulation
            these are swapped among replicas.

        See Also
        --------
        read_replica_thermodynamic_states

        """
        # Retrieve group and number of states.
        ncgrp_states = self._ncfile.groups['thermodynamic_states']
        n_states = self._ncfile.dimensions['replica'].size

        # Read state information.
        thermodynamic_states = list()
        for state_index in range(n_states):
            # Reconstitute System object.
            system = openmm.System()
            system.__setstate__(ncgrp_states.variables['systems'][state_index])

            # Read temperature and pressure (if NPT).
            temperature = ncgrp_states.variables['temperatures'][state_index] * unit.kelvin
            if 'pressures' in ncgrp_states.variables:
                pressure = ncgrp_states.variables['pressures'][state_index] * unit.atmospheres
            else:
                pressure = None

            # Create ThermodynamicState.
            thermodynamic_states.append(mmtools.states.ThermodynamicState(system=system, temperature=temperature,
                                                                          pressure=pressure))

        return thermodynamic_states

    @mmtools.utils.with_timer('Storing thermodynamic states')
    def write_thermodynamic_states(self, thermodynamic_states):
        """Store all the ThermodynamicStates.

        Parameters
        ----------
        thermodynamic_states : list of ThermodynamicState
            The thermodynamic states to store.

        See Also
        --------
        write_replica_thermodynamic_states

        """
        n_states = len(thermodynamic_states)
        is_barostated = thermodynamic_states[0].pressure is not None

        # Create a group to store state information.
        ncgrp_states = self._ncfile.createGroup('thermodynamic_states')

        # Check if replica dimensions exist.
        if 'replica' not in self._ncfile.dimensions:
            self._ncfile.createDimension('replica', n_states)

        # Store number of states.
        ncvar_nstates = ncgrp_states.createVariable('nstates', int)
        ncvar_nstates.assignValue(n_states)

        # Create variables.
        ncvar_serialized_systems = ncgrp_states.createVariable('systems', str, ('replica',), zlib=True)
        setattr(ncvar_serialized_systems, 'long_name',
                "systems[state] is the serialized OpenMM System corresponding to the thermodynamic state 'state'")

        ncvar_temperatures = ncgrp_states.createVariable('temperatures', 'f', ('replica',))
        setattr(ncvar_temperatures, 'units', 'K')
        setattr(ncvar_temperatures, 'long_name',
                "temperatures[state] is the temperature of thermodynamic state 'state'")

        if is_barostated:
            ncvar_pressures = ncgrp_states.createVariable('pressures', 'f', ('replica',))
            setattr(ncvar_pressures, 'units', 'atm')
            setattr(ncvar_pressures, 'long_name',
                    "pressures[state] is the external pressure of thermodynamic state 'state'")

        # Store all thermodynamic states
        for state_id, thermodynamic_state in enumerate(thermodynamic_states):
            serialized = thermodynamic_state.system.__getstate__()
            logger.debug("Serialized state {} is  {}B | {:.3f}KB | {:.3f}MB".format(
                state_id, len(serialized), len(serialized) / 1024.0, len(serialized) / 1024.0 / 1024.0))
            ncvar_serialized_systems[state_id] = serialized

            ncvar_temperatures[state_id] = thermodynamic_state.temperature / unit.kelvin
            if is_barostated:
                ncvar_pressures[state_id] = thermodynamic_state.pressure / unit.atmospheres

    def read_sampler_states(self, iteration):
        """Retrieve the stored sampler states.

        Parameters
        ----------
        iteration : int
            The iteration at which to read the data.

        Returns
        -------
        sampler_states : list of SamplerStates
            The previously stored sampler states for each replica.

        """
        n_states = self._ncfile.dimensions['replica'].size

        sampler_states = list()
        for replica_index in range(n_states):
            # Restore positions.
            x = self._ncfile.variables['positions'][iteration, replica_index, :, :].astype(np.float64)
            positions = unit.Quantity(x, unit.nanometers)

            # Restore box vectors.
            x = self._ncfile.variables['box_vectors'][iteration, replica_index, :, :].astype(np.float64)
            box_vectors = unit.Quantity(x, unit.nanometers)

            # Create SamplerState.
            sampler_states.append(mmtools.states.SamplerState(positions=positions, box_vectors=box_vectors))

        return sampler_states

    @mmtools.utils.with_timer('Storing sampler states')
    def write_sampler_states(self, sampler_states, iteration):
        """Store all sampler states for a given iteration.

        Parameters
        ----------
        sampler_states : list of SamplerStates
            The sampler states to store for each replica.
        iteration : int
            The iteration at which to store the data.

        """
        # Check if the schema must be initialized.
        if 'positions' not in self._ncfile.variables:
            n_atoms = sampler_states[0].n_particles
            n_states = len(sampler_states)

            # Create dimensions. Replica dimension could have been created before.
            self._ncfile.createDimension('atom', n_atoms)
            if 'replica' not in self._ncfile.dimensions:
                self._ncfile.createDimension('replica', n_states)

            # Create variables.
            ncvar_positions = self._ncfile.createVariable('positions', 'f4',
                                                          ('iteration', 'replica', 'atom', 'spatial'),
                                                          zlib=True, chunksizes=(1, n_states, n_atoms, 3))
            ncvar_box_vectors = self._ncfile.createVariable('box_vectors', 'f4',
                                                            ('iteration', 'replica', 'spatial', 'spatial'),
                                                            zlib=False, chunksizes=(1, n_states, 3, 3))
            ncvar_volumes = self._ncfile.createVariable('volumes', 'f8', ('iteration', 'replica'),
                                                        zlib=False, chunksizes=(1, n_states))

            # Define units for variables.
            setattr(ncvar_positions, 'units', 'nm')
            setattr(ncvar_box_vectors, 'units', 'nm')
            setattr(ncvar_volumes, 'units', 'nm**3')

            # Define long (human-readable) names for variables.
            setattr(ncvar_positions, "long_name", ("positions[iteration][replica][atom][spatial] is position of "
                                                   "coordinate 'spatial' of atom 'atom' from replica 'replica' for "
                                                   "iteration 'iteration'."))

            setattr(ncvar_box_vectors, "long_name", ("box_vectors[iteration][replica][i][j] is dimension j of box "
                                                     "vector i for replica 'replica' from iteration 'iteration-1'."))
            setattr(ncvar_volumes, "long_name", ("volume[iteration][replica] is the box volume for replica 'replica' "
                                                 "from iteration 'iteration-1'."))

        # Store sampler states.
        for replica_index, sampler_state in enumerate(sampler_states):
            # Store positions
            x = sampler_state.positions / unit.nanometers
            self._ncfile.variables['positions'][iteration, replica_index, :, :] = x[:, :]

            # Store box vectors and volume.
            for i in range(3):
                vector_i = sampler_state.box_vectors[i] / unit.nanometers
                self._ncfile.variables['box_vectors'][iteration, replica_index, i, :] = vector_i
            self._ncfile.variables['volumes'][iteration, replica_index] = sampler_state.volume / unit.nanometers**3

    def read_replica_thermodynamic_states(self, iteration):
        """Retrieve the indices of the ThermodynamicStates for each replica.

        Parameters
        ----------
        iteration : int
            The iteration at which to read the data.

        Returns
        -------
        state_indices : list of int
            At the given iteration, replica i propagated the system in
            SamplerState sampler_states[i] and ThermodynamicState
            thermodynamic_states[states_indices[i]].

        """
        return self._ncfile.variables['states'][iteration]

    def write_replica_thermodynamic_states(self, state_indices, iteration):
        """Store the indices of the ThermodynamicStates for each replica.

        Parameters
        ----------
        state_indices : list of int
            At the given iteration, replica i propagated the system in
            SamplerState sampler_states[i] and ThermodynamicState
            thermodynamic_states[replica_thermodynamic_states[i]].
        iteration : int
            The iteration at which to store the data.

        """
        # Initialize schema if needed.
        if 'states' not in self._ncfile.variables:
            n_states = len(state_indices)

            # Create dimension if they don't exist.
            if 'replica' not in self._ncfile.dimensions:
                self._ncfile.createDimension('replica', n_states)

            # Create variables and attach units and description.
            ncvar_states = self._ncfile.createVariable('states', 'i4', ('iteration', 'replica'),
                                                       zlib=False, chunksizes=(1, n_states))
            setattr(ncvar_states, 'units', 'none')
            setattr(ncvar_states, "long_name", ("states[iteration][replica] is the thermodynamic state index "
                                                "(0..nstates-1) of replica 'replica' of iteration 'iteration'."))

        # Store thermodynamic states indices.
        self._ncfile.variables['states'][iteration, :] = state_indices[:]

    def read_mcmc_moves(self):
        """Return the MCMCMoves of the ReplicaExchange simulation.

        Returns
        -------
        mcmc_moves : list of MCMCMove
            The MCMCMoves used to propagate the simulation.

        """
        mcmc_moves = list()

        # Get group storing MCMCMoves.
        ncgrp = self._ncfile.groups['mcmc_moves']

        # Retrieve all moves in order.
        for i in range(len(ncgrp.groups)):
            serialized_move = self._read_dict(ncgrp.groups['move' + str(i)])
            mcmc_moves.append(mmtools.utils.deserialize(serialized_move))
        return mcmc_moves

    def write_mcmc_moves(self, mcmc_moves):
        """Store the MCMCMoves of the ReplicaExchange simulation.

        Parameters
        ----------
        mcmc_moves : list of MCMCMove
            The MCMCMoves used to propagate the simulation.

        """
        # Serialize and store MCMCMoves.
        for i, mcmc_move in enumerate(mcmc_moves):
            serialized_move = mmtools.utils.serialize(mcmc_move)
            self.write_dict('mcmc_moves/move' + str(i), serialized_move)

    def read_energies(self, iteration):
        """Retrieve the energy matrix at the given iteration.

        Parameters
        ----------
        iteration : int
            The iteration at which to read the data.

        Returns
        -------
        energy_matrix : kxk numpy.ndarray
            energy_matrix[i][j] is the reduced potential computed at SamplerState
            sampler_states[i] and ThermodynamicState thermodynamic_states[j].

        """
        return self._ncfile.variables['energies'][iteration]

    def write_energies(self, energy_matrix, iteration):
        """Store the energy matrix at the given iteration.

        Parameters
        ----------
        energy_matrix : kxk numpy.ndarray
            energy_matrix[i][j] is the reduced potential computed at SamplerState
            sampler_states[i] and ThermodynamicState thermodynamic_states[j].
        iteration : int
            The iteration at which to store the data.

        """
        # Initialize schema if needed.
        if 'energies' not in self._ncfile.variables:
            n_states = len(energy_matrix)

            # Create dimension if it wasn't created by other functions.
            if 'replica' not in self._ncfile.dimensions:
                self._ncfile.createDimension('replica', n_states)

            # Create variable with its units and descriptions.
            ncvar_energies = self._ncfile.createVariable('energies', 'f8', ('iteration', 'replica', 'replica'),
                                                         zlib=False, chunksizes=(1, n_states, n_states))
            setattr(ncvar_energies, 'units', 'kT')
            setattr(ncvar_energies, "long_name", ("energies[iteration][replica][state] is the reduced (unitless) "
                                                  "energy of replica 'replica' from iteration 'iteration' evaluated "
                                                  "at state 'state'."))

        # Store energy.
        self._ncfile.variables['energies'][iteration, :, :] = energy_matrix[:, :]

    def read_mixing_statistics(self, iteration):
        """Retrieve the mixing statistics for the given iteration.

        Parameters
        ----------
        iteration : int
            The iteration at which to read the data.

        Returns
        -------
        n_accepted_matrix : kxk numpy.ndarray
            n_accepted_matrix[i][j] is the number of accepted moves from
            state thermodynamic_states[i] to thermodynamic_states[j] going
            from iteration-1 to iteration (not cumulative).
        n_proposed_matrix : kxk numpy.ndarray
            n_proposed_matrix[i][j] is the number of proposed moves from
            state thermodynamic_states[i] to thermodynamic_states[j] going
            from iteration-1 to iteration (not cumulative).

        """
        n_accepted_matrix = self._ncfile.variables['accepted'][iteration, :, :]
        n_proposed_matrix = self._ncfile.variables['proposed'][iteration, :, :]
        return n_accepted_matrix, n_proposed_matrix

    def write_mixing_statistics(self, n_accepted_matrix, n_proposed_matrix, iteration):
        """Store the mixing statistics for the given iteration.

        Parameters
        ----------
        n_accepted_matrix : kxk numpy.ndarray
            n_accepted_matrix[i][j] is the number of accepted moves from
            state thermodynamic_states[i] to thermodynamic_states[j] going
            from iteration-1 to iteration (not cumulative).
        n_proposed_matrix : kxk numpy.ndarray
            n_proposed_matrix[i][j] is the number of proposed moves from
            state thermodynamic_states[i] to thermodynamic_states[j] going
            from iteration-1 to iteration (not cumulative).
        iteration : int
            The iteration at which to store the data.

        """
        # Create schema if necessary.
        if 'accepted' not in self._ncfile.variables:
            n_states = len(n_accepted_matrix)

            # Create replica dimension if it wasn't already created.
            if 'replica' not in self._ncfile.dimensions:
                self._ncfile.createDimension('replica', n_states)

            # Create variables with units and descriptions.
            ncvar_accepted = self._ncfile.createVariable('accepted', 'i4', ('iteration', 'replica', 'replica'),
                                                         zlib=False, chunksizes=(1, n_states, n_states))
            ncvar_proposed = self._ncfile.createVariable('proposed', 'i4', ('iteration', 'replica', 'replica'),
                                                         zlib=False, chunksizes=(1, n_states, n_states))
            setattr(ncvar_accepted, 'units', 'none')
            setattr(ncvar_proposed, 'units', 'none')
            setattr(ncvar_accepted, 'long_name', ("accepted[iteration][i][j] is the number of proposed transitions "
                                                  "between states i and j from iteration 'iteration-1'."))
            setattr(ncvar_proposed, 'long_name', ("proposed[iteration][i][j] is the number of proposed transitions "
                                                  "between states i and j from iteration 'iteration-1'."))

        # Store statistics.
        self._ncfile.variables['accepted'][iteration, :, :] = n_accepted_matrix[:, :]
        self._ncfile.variables['proposed'][iteration, :, :] = n_proposed_matrix[:, :]

    def read_timestamp(self, iteration):
        """Return the timestamp for the given iteration.

        Parameters
        ----------
        iteration : int
            The iteration at which to read the data.

        Returns
        -------
        timestamp : str
            The timestamp at which the iteration was stored.

        """
        return self._ncfile.variables['timestamp'][iteration]

    def write_timestamp(self, iteration):
        """Store a timestamp for the given iteration.

        Parameters
        ----------
        iteration : int
            The iteration at which to read the data.

        """
        # Create variable if needed.
        if 'timestamp' not in self._ncfile.variables:
            self._ncfile.createVariable('timestamp', str, ('iteration',), zlib=False, chunksizes=(1,))
        self._ncfile.variables['timestamp'][iteration] = time.ctime()

    def read_dict(self, name):
        """Restore a dictionary from the storage file.

        Parameters
        ----------
        name : str
            The identifier of the dictionary used to stored the data.

        Returns
        -------
        data : dict
            The restored data as a dict.

        """
        ncgrp = self._ncfile.groups[name]
        return self._read_dict(ncgrp)

    def write_dict(self, name, data):
        """Store the contents of a dict.

        Parameters
        ----------
        name : str
            The identifier of the dictionary in the storage file.
        data : dict
            The dict to store.

        """
        # Create group.
        ncgrp = self._ncfile.createGroup(name)

        for key, value in data.items():
            # If Quantity, strip off units first.
            value_unit = None
            if isinstance(value, unit.Quantity):
                value_unit = value.unit
                value = value / value_unit

            # Check the Python type.
            value_type = type(value)
            stored_type_name = utils.typename(value_type)

            # We store booleans as integers.
            if isinstance(value, bool):
                # Keep stored_type_name as bool to store original type.
                value = int(value)
                value_type = int

            # Store the variable.
            if isinstance(value, dict):
                # Nested dictionary in a subgroup.
                self.write_dict(name + '/' + key, value)
                # No need to store ncvar type as this will be marked as group.
                ncvar = None
            elif isinstance(value, str):
                ncvar = ncgrp.createVariable(key, value_type, 'scalar')
                packed_data = np.empty(1, 'O')
                packed_data[0] = value
                ncvar[:] = packed_data
            elif isinstance(value, collections.Iterable):
                # Cast as numpy array to check shape and extract the element
                # type. np.ravel() returns a view, it doesn't allocate memory.
                value = np.array(value)
                element_type = type(value.ravel()[0])
                element_type_name = utils.typename(element_type)

                # Create dimensions and variable.
                dimensions_names = tuple([key + 'dimension' + str(i) for i in range(len(value.shape))])
                for dimension_name, dimension in zip(dimensions_names, value.shape):
                    ncgrp.createDimension(dimension_name, dimension)
                ncvar = ncgrp.createVariable(key, element_type, dimensions_names)

                # Store values and element type.
                ncvar[:] = value[:]
                stored_type_name = element_type_name
            elif value is None:
                ncvar = ncgrp.createVariable(key, int)
                ncvar.assignValue(0)
            else:
                ncvar = ncgrp.createVariable(key, value_type)
                ncvar.assignValue(value)

            # Set the type of the variable if this wasn't a dictionary.
            if ncvar is not None:
                setattr(ncvar, 'type', stored_type_name)

            # Log value (truncate if too long but save length)
            if hasattr(value, '__len__'):
                logger.debug("Storing option: {} -> {} (type: {}, length {})".format(
                    key, str(value)[:100], stored_type_name, len(value)))
            else:
                logger.debug("Storing option: {} -> {} (type: {})".format(
                    key, value, stored_type_name))
            if value_unit is not None:
                setattr(ncvar, 'units', str(value_unit))

    # -------------------------------------------------------------------------
    # Internal-usage
    # -------------------------------------------------------------------------

    def _read_dict(self, ncgrp):
        """Read and return a dictionary.

        Takes a group instead of a name to resolve nested dictionaries.

        """
        data = dict()

        # Restore nested dictionaries.
        for name, nested_ncgrp in ncgrp.groups.items():
            data[name] = self._read_dict(nested_ncgrp)

        # Restore variables.
        for key, ncvar in ncgrp.variables.items():
            type_name = getattr(ncvar, 'type')
            # TODO: Remove the if/elseif structure into one handy function
            # Get option value.
            if type_name == 'NoneType':
                value = None
            else:  # Handle all Types not None
                value_type = self._convert_netcdf_store_type(type_name)
                if ncvar.shape == ():  # Standard Types
                    value = value_type(ncvar.getValue())
                elif ncvar.shape[0] >= 0:  # Array types
                    value = np.array(ncvar[:], value_type)
                    if issubclass(value_type, str):
                        value = value_type(value[0])
                else:
                    raise ValueError('Cannot restore type {} with value {}'.format(
                        value_type, ncvar.getValue()))

            # If Quantity, assign unit.
            if hasattr(ncvar, 'units'):
                value_unit_name = getattr(ncvar, 'units')
                if value_unit_name[0] == '/':
                    value_unit = utils.quantity_from_string(value_unit_name[1:])
                    value = value / value_unit
                else:
                    value_unit = utils.quantity_from_string(value_unit_name)
                    value = value * value_unit

            # Log value (truncate if too long but save length)
            if hasattr(value, '__len__'):
                try:
                    value_len = len(value)
                except TypeError:  # this is a zero-dimensional array
                    value_len = np.atleast_1d(value)
                logger.debug("Restoring option: {} -> {} (type: {}, length {})".format(
                    key, str(value)[:500], type(value), value_len))
            else:
                logger.debug("Restoring option: {} -> {} (type: {})".format(
                    key, value, type(value)))

            # Store option.
            data[key] = value

        return data

    @staticmethod
    def _convert_netcdf_store_type(stored_type):
        """
        Convert the stored NetCDF datatype from string to type without relying on unsafe eval() function

        Parameters
        ----------
        stored_type : string
            Read from ncfile.Variable.type stored by repex

        Returns
        -------
        proper_type : type
            Python or module type

        """
        try:
            # Check if it's a builtin type
            try:  # Python 2
                module = importlib.import_module('__builtin__')
            except:  # Python 3
                module = importlib.import_module('builtins')
            proper_type = getattr(module, stored_type)
        except AttributeError:
            # if not, separate module and class
            module, stored_type = stored_type.rsplit(".", 1)
            module = importlib.import_module(module)
            proper_type = getattr(module, stored_type)
        return proper_type


# ==============================================================================
# REPLICA-EXCHANGE SIMULATION
# ==============================================================================

class ReplicaExchange(object):
    """
    Replica-exchange simulation facility.

    This base class provides a general replica-exchange simulation facility, allowing any set of thermodynamic states
    to be specified, along with a set of initial positions to be assigned to the replicas in a round-robin fashion.
    No distinction is made between one-dimensional and multidimensional replica layout; by default, the replica mixing
    scheme attempts to mix *all* replicas to minimize slow diffusion normally found in multidimensional replica exchange
    simulations.  (Modification of the 'replica_mixing_scheme' setting will allow the tranditional 'neighbor swaps only'
    scheme to be used.)

    While this base class is fully functional, it does not make use of the special structure of parallel tempering or
    Hamiltonian exchange variants of replica exchange.  The ParallelTempering and HamiltonianExchange classes should
    therefore be used for these algorithms, since they are more efficient and provide more convenient ways to initialize
    the simulation classes.

    Stored configurations, energies, swaps, and restart information are all written to a single output file using
    the platform portable, robust, and efficient NetCDF4 library.  Plans for future HDF5 support are pending.

    Attributes
    ----------
    The following parameters (attributes) can be set after the object has been created, but before it has been
    initialized by a call to run():

    collision_rate : simtk.unit.Quantity (units: 1/time)
       The collision rate used for Langevin dynamics (default: 90 ps^-1)
    constraint_tolerance : float
       Relative constraint tolerance (default: 1e-6)
    timestep : simtk.unit.Quantity (units: time)
       Timestep for Langevin dyanmics (default: 2 fs)
    nsteps_per_iteration : int
       Number of timesteps per iteration (default: 500)
    number_of_iterations : int
       Number of replica-exchange iterations to simulate (default: 100)
    number_of_equilibration_iterations : int
       Number of equilibration iterations before beginning exchanges (default: 0)
    equilibration_timestep : simtk.unit.Quantity (units: time)
       Timestep for use in equilibration (default: 2 fs)
    title : str
       Title for the simulation.
    minimize : bool
       Minimize configurations before running the simulation (default: True)
    minimize_tolerance : simtk.unit.Quantity (units: energy/mole/length)
       Set minimization tolerance (default: 1.0 * unit.kilojoules_per_mole / unit.nanometers).
    minimize_max_iterations : int
       Maximum number of iterations for minimization.
    replica_mixing_scheme : str
       Specify how to mix replicas. Supported schemes are 'swap-neighbors' and
       'swap-all' (default: 'swap-all').
    online_analysis : bool
       If True, analysis will occur each iteration (default: False).
    online_analysis_min_iterations : int
       Minimum number of iterations needed to begin online analysis (default: 20).
    show_energies : bool
       If True, will print energies at each iteration (default: True).
    show_mixing_statistics : bool
       If True, will show mixing statistics at each iteration (default: True).

    TODO
    ----
    * Replace hard-coded Langevin dynamics with general MCMC moves.
    * Allow parallel resource to be used, if available (likely via Parallel Python).
    * Add support for and autodetection of other NetCDF4 interfaces.
    * Add HDF5 support.

    Examples
    --------
    Parallel tempering simulation of alanine dipeptide in implicit solvent (replica exchange among temperatures)
    (This is just an illustrative example; use ParallelTempering class for actual production parallel tempering simulations.)

    >>> # Create test system.
    >>> from openmmtools import testsystems
    >>> testsystem = testsystems.AlanineDipeptideImplicit()
    >>> [system, positions] = [testsystem.system, testsystem.positions]
    >>> # Create thermodynamic states for parallel tempering with exponentially-spaced schedule.
    >>> from simtk import unit
    >>> import math
    >>> nreplicas = 3 # number of temperature replicas
    >>> T_min = 298.0 * unit.kelvin # minimum temperature
    >>> T_max = 600.0 * unit.kelvin # maximum temperature
    >>> T_i = [ T_min + (T_max - T_min) * (math.exp(float(i) / float(nreplicas-1)) - 1.0) / (math.e - 1.0) for i in range(nreplicas) ]
    >>> states = [ ThermodynamicState(system=system, temperature=T_i[i]) for i in range(nreplicas) ]
    >>> import tempfile
    >>> store_filename = tempfile.NamedTemporaryFile(delete=False).name + '.nc'
    >>> # Create simulation.
    >>> simulation = ReplicaExchange(store_filename)
    >>> simulation.create(states, positions) # initialize the replica-exchange simulation
    >>> simulation.minimize = False
    >>> simulation.number_of_iterations = 2 # set the simulation to only run 2 iterations
    >>> simulation.timestep = 2.0 * unit.femtoseconds # set the timestep for integration
    >>> simulation.nsteps_per_iteration = 50 # run 50 timesteps per iteration
    >>> simulation.run() # run the simulation
    >>> del simulation # clean up

    Extend the simulation

    >>> simulation = ReplicaExchange(store_filename)
    >>> simulation.resume()
    >>> simulation.number_of_iterations = 4 # extend
    >>> simulation.run()

    Clean up.

    >>> os.remove(store_filename)

    """

    default_parameters = {'collision_rate': 5.0 / unit.picosecond,
                          'constraint_tolerance': 1.0e-6,
                          'timestep': 2.0 * unit.femtosecond,
                          'nsteps_per_iteration': 500,
                          'number_of_iterations': 1,
                          'extend_simulation': False,  # Do not save this option as its an on-the-fly setting
                          'equilibration_timestep': 1.0 * unit.femtosecond,
                          'number_of_equilibration_iterations': 1,
                          'title': 'Replica-exchange simulation created using ReplicaExchange class of repex.py on %s' % time.asctime(time.localtime()),
                          'minimize': True,
                          'minimize_tolerance': 1.0 * unit.kilojoules_per_mole / unit.nanometers,
                          'minimize_max_iterations': 0,
                          'replica_mixing_scheme': 'swap-all',
                          'online_analysis': False,
                          'online_analysis_min_iterations': 20,
                          'show_energies': True,
                          'show_mixing_statistics': True
                          }

    # Options to store.
    options_to_store = ['collision_rate', 'constraint_tolerance', 'timestep', 'nsteps_per_iteration',
                        'number_of_iterations', 'equilibration_timestep', 'number_of_equilibration_iterations', 'title',
                        'minimize', 'replica_mixing_scheme', 'online_analysis', 'show_mixing_statistics']

    def __init__(self, mcmc_moves=None,
                 number_of_iterations=1,
                 replica_mixing_scheme='swap-all',
                 online_analysis=False,
                 online_analysis_min_iterations=20,
                 show_energies=True,
                 show_mixing_statistics=True):
        """
        Initialize replica-exchange simulation facility.

        Parameters
        ----------
        store_filename : string
           Name of file to bind simulation to use as storage for checkpointing and storage of results.
        mm : implementation of simtk.openmm, optional, default=simtk.openmm
           OpenMM API implementation to use
        mpicomm : mpi4py communicator, optional, default=None
           MPI communicator, if parallel execution is desired
        platform : simtk.openmm.Platform, optional, default=None
            Platform to use for execution. If None, the fastest available platform is used.

        Other Parameters
        ----------------
        **kwargs
            Parameters in ReplicaExchange.default_parameters corresponding public attributes.

        """
        # Handling default propagator.
        if mcmc_moves is None:
            # This will be converted to a list in create().
            mcmc_moves = mmtools.mcmc.LangevinDynamicsMove(timestep=2.0*unit.femtosecond,
                                                           collision_rate=5.0/unit.picosecond,
                                                           n_steps=500)
        self._mcmc_moves = copy.deepcopy(mcmc_moves)

        # Store constructor parameters. Everything is marked for internal
        # usage because any change to these attribute would imply a change
        # in the storage file as well, which we don't currently support.
        self._number_of_iterations = number_of_iterations
        self._replica_mixing_scheme = replica_mixing_scheme
        self._online_analysis = online_analysis
        self._online_analysis_min_iterations = online_analysis_min_iterations
        self._show_energies = show_energies
        self._show_mixing_statistics = show_mixing_statistics

        # These will be set on initialization. See function
        # create() for explanation of single variables.
        self._thermodynamic_states = None
        self._sampler_states = None
        self._replica_thermodynamic_states = None
        self._iteration = None
        self._u_kl = None
        self._n_accepted_matrix = None
        self._n_proposed_matrix = None
        self._reporter = None  # This is None everywhere but in node 0

    @classmethod
    def from_storage(cls, storage):
        """Constructor from an existing storage file.

        Parameters
        ----------
        storage : str
            The path to the storage file. In the future this will be able
            to take a Reporter or a Storage class as well.

        Returns
        -------
        repex : ReplicaExchange
            A new instance of ReplicaExchange in the same state of the
            last stored iteration.

        """
        # Check if netcdf file exists.
        file_exists = cls._does_file_exist(storage)
        if not file_exists:
            raise RuntimeError('Storage file {} does not exists; cannot resume.'.format(storage))

        # Open a reporter to read the data.
        reporter = Reporter(storage, mode='r')

        # Retrieve options and create new simulation.
        options = reporter.read_dict('options')
        options['mcmc_moves'] = reporter.read_mcmc_moves()
        repex = ReplicaExchange(**options)

        # Display papers to be cited.
        repex._display_citations()

        # Retrieve other attributes.
        logger.debug("Reading storage file {}...".format(storage))
        thermodynamic_states = reporter.read_thermodynamic_states()
        sampler_states = reporter.read_sampler_states(iteration=-1)
        state_indices = reporter.read_replica_thermodynamic_states(iteration=-1)
        energies = reporter.read_energies(iteration=-1)
        n_accepted_matrix, n_proposed_matrix = reporter.read_mixing_statistics(iteration=-1)

        # Count timestamps to retrieve the current number of iterations.
        iteration = len(reporter.read_timestamp(iteration=slice(None))) - 1  # 0-based

        # Assign attributes.
        repex._thermodynamic_states = thermodynamic_states
        repex._sampler_states = sampler_states
        repex._replica_thermodynamic_states = state_indices
        repex._u_kl = energies
        repex._n_accepted_matrix = n_accepted_matrix
        repex._n_proposed_matrix = n_proposed_matrix
        repex._iteration = iteration

        # We set the reporter in node 0. Will return None if not rank 0.
        repex._reporter = mpi.run_single_node(0, Reporter, storage, mode='a',
                                              broadcast_result=False, sync_nodes=False)
        return repex

    @property
    def n_replicas(self):
        """The number of replicas (read-only)."""
        if self._thermodynamic_states is None:
            return 0
        else:
            return len(self._thermodynamic_states)

    @property
    def iteration(self):
        """The current iteration of the simulation (read-only).

        If the simulation has not been initialized, this is None.

        """
        return self._iteration

    def create(self, thermodynamic_states, sampler_states, storage, metadata=None):
        """
        Create new replica-exchange simulation.

        Parameters
        ----------
        states : list of ThermodynamicState
           Thermodynamic states to simulate, where one replica is allocated per state.
           Each state must have a system with the same number of atoms, and the same
           thermodynamic ensemble (combination of temperature, pressure, pH, etc.) must
           be defined for each.
        positions : Coordinate object or iterable container of Coordinate objects)
           One or more sets of initial positions
           to be initially assigned to replicas in a round-robin fashion, provided simulation is not resumed from store file.
           Currently, positions must be specified as a list of simtk.unit.Quantity-wrapped np arrays.
        options : dict, optional, default=None
           Optional dict to use for specifying simulation options. Provided keywords will be matched to object variables to replace defaults.
        metadata : dict, optional, default=None
           metadata to store in a 'metadata' group in store file

        """
        # Check if netcdf file exists. This is run only on MPI node 0 and
        # broadcasted. This is to avoid the case where the other nodes
        # arrive to this line after node 0 has already created the storage
        # file, causing an error.
        file_exists = mpi.run_single_node(0, self._does_file_exist, storage, broadcast_result=True)
        if file_exists:
            raise RuntimeError("Storage file {} already exists; cowardly "
                               "refusing to overwrite.".format(storage))

        # Make sure sampler_states is an iterable of SamplerStates for later.
        if isinstance(sampler_states, mmtools.states.SamplerState):
            sampler_states = [sampler_states]

        # Make sure there are no more sampler states than thermodynamic states.
        if len(sampler_states) > len(thermodynamic_states):
            raise ValueError('Passed {} SamplerStates but only {} ThermodynamicStates'.format(
                len(sampler_states), len(thermodynamic_states)))

        # Make sure all states have same number of particles. We don't
        # currently support writing storage with different n_particles
        n_particles = thermodynamic_states[0].n_particles
        for states in [thermodynamic_states, sampler_states]:
            for state in states:
                if state.n_particles != n_particles:
                    raise ValueError('All ThermodynamicStates and SamplerStates must '
                                     'have the same number of particles')

        # Save thermodynamic states. This sets n_replicas.
        self._thermodynamic_states = copy.deepcopy(thermodynamic_states)

        # Distribute sampler states to replicas in a round-robin fashion.
        self._sampler_states = [copy.deepcopy(sampler_states[i % len(sampler_states)])
                                for i in range(self.n_replicas)]

        # Map each thermodynamic state to a replica. Replica i at each iteration is
        # in ThermodynamicState thermodynamic_states[replica_thermodynamic_states[i]]
        # and SamplerState sampler_states[i]. During mixing, we exchange the indices
        # of the ThermodynamicState, but we keep the SamplerStates (i.e. positions,
        # velocities, box_vectors) bound to the same replica.
        self._replica_thermodynamic_states = np.array([i for i in range(self.n_replicas)], np.int32)

        # Assign default system box vectors if None has been specified.
        for replica_id, thermodynamic_state_id in enumerate(self._replica_thermodynamic_states):
            sampler_state = self._sampler_states[replica_id]
            if sampler_state.box_vectors is not None:
                continue
            thermodynamic_state = self._thermodynamic_states[thermodynamic_state_id]
            sampler_state.box_vectors = thermodynamic_state.system.getDefaultPeriodicBoxVectors()

        # Ensure there is an MCMCMove for each replica.
        if isinstance(self._mcmc_moves, mmtools.mcmc.MCMCMove):
            self._mcmc_moves = [copy.deepcopy(self._mcmc_moves) for _ in range(self.n_replicas)]
        elif len(self._mcmc_moves) != self.n_replicas:
            raise RuntimeError('The number of MCMCMoves ({}) and ThermodynamicStates ({}) must '
                               'be the same.'.format(len(self._mcmc_moves), self.n_replicas))

        # Reset iteration counter.
        self._iteration = 0

        # Reset statistics.
        # _n_accepted_matrix[i][j] is the number of swaps proposed between thermodynamic states i and j.
        # _n_proposed_matrix[i][j] is the number of swaps proposed between thermodynamic states i and j.
        self._n_accepted_matrix = np.zeros([self.n_replicas, self.n_replicas], np.int32)
        self._n_proposed_matrix = np.zeros([self.n_replicas, self.n_replicas], np.int32)

        # Allocate memory for energy matrix.
        # u_kl[k][l] is the reduced potential computed at the positions of SamplerState
        # sampler_states[k] and ThermodynamicState thermodynamic_states[l].
        self._u_kl = np.zeros([self.n_replicas, self.n_replicas], np.float64)

        # Display papers to be cited.
        self._display_citations()

        # Initialize NetCDF file.
        self._initialize_reporter(storage, metadata)

    @mmtools.utils.with_timer('Minimizing all replicas')
    def minimize(self, minimize_tolerance=1.0*unit.kilojoules_per_mole/unit.nanometers,
                 minimize_max_iterations=0):
        logger.debug("Minimizing all replicas...")

        # Distribute minimization across nodes. Only node 0 will get all positions.
        # The other nodes, only need the positions that they use for propagation and
        # computation of the energies.
        minimized_positions, sampler_state_ids = mpi.distribute(self._minimize_replica, range(self.n_replicas),
                                                                minimize_tolerance, minimize_max_iterations,
                                                                send_results_to=0)

        # Update all sampler states. For non-0 nodes, this will update only the
        # sampler states associated to the replicas propagated by this node.
        for sampler_state_id in sampler_state_ids:
            self._sampler_states[sampler_state_id].positions = minimized_positions[sampler_state_id]

        # Save the stored positions in the storage
        if self._reporter is not None:
            mpi.run_single_node(0, self._reporter.write_sampler_states, self._sampler_states, self._iteration)

    def __repr__(self):
        """
        Return a 'formal' representation that can be used to reconstruct the class, if possible.

        """

        # TODO: Can we make this a more useful expression?
        return "<instance of ReplicaExchange>"

    def __str__(self):
        """
        Show an 'informal' human-readable representation of the replica-exchange simulation.

        """

        r =  ""
        r += "Replica-exchange simulation\n"
        r += "\n"
        r += "{:d} replicas\n".format(self.nreplicas)
        r += "{:d} coordinate sets provided\n".format(len(self.provided_positions))
        r += "file store: {:s}\n".format(self.store_filename)
        r += "initialized: {:s}\n".format(self._initialized)
        r += "\n"
        r += "PARAMETERS\n"
        r += "collision rate: {:s}\n".format(self.collision_rate)
        r += "relative constraint tolerance: {:s}\n".format(self.constraint_tolerance)
        r += "timestep: {:s}\n".format(self.timestep)
        r += "number of steps/iteration: {:d}\n".format(self.nsteps_per_iteration)
        r += "number of iterations: {:d}\n".format(self.number_of_iterations)
        if self.extend_simulation:
            r += "Iterations extending existing data.\n"
        r += "equilibration timestep: {:s}\n".format(self.equilibration_timestep)
        r += "number of equilibration iterations: {:d}\n".format(self.number_of_equilibration_iterations)
        r += "\n"

        return r

    def run(self, niterations_to_run=None):
        """
        Run the replica-exchange simulation.

        Any parameter changes (via object attributes) that were made between object creation and calling this method become locked in
        at this point, and the object will create and bind to the store file.  If the store file already exists, the run will be resumed
        if possible; otherwise, an exception will be raised.

        Parameters
        ----------
        niterations_to_run : int, optional, default=None
           If specfied, only at most the specified number of iterations will be run.

        """
        if not self._initialized:
            self._initialize_resume()

        # Log platform configuration
        if self.platform is None:
            logger.info('No user-specified platform found. Will run with OpenMM default.')
        else:
            logger.info('Running with platform {}'.format(self.platform.getName()))

        # Main loop
        run_start_time = time.time()
        run_start_iteration = self.iteration
        default_iteration_limit = self.number_of_iterations
        if self.extend_simulation:
            default_iteration_limit += self.iteration
        if niterations_to_run:
            iteration_limit = min(self.iteration + niterations_to_run, default_iteration_limit)
        else:
            iteration_limit = default_iteration_limit
        while (self.iteration < iteration_limit):
            logger.debug("\nIteration %d / %d" % (self.iteration+1, iteration_limit))
            initial_time = time.time()

            # Attempt replica swaps to sample from equilibrium permuation of states associated with replicas.
            self._mix_replicas()

            # Propagate replicas.
            self._propagate_replicas()

            # Compute energies of all replicas at all states.
            self._compute_energies()

            # Show energies.
            if self.show_energies:
                self._show_energies()

            # Write iteration to storage file.
            self._write_iteration_netcdf()

            # Increment iteration counter.
            self.iteration += 1

            # Show mixing statistics.
            if self.show_mixing_statistics:
                self._show_mixing_statistics()

            # Perform online analysis.
            if self.online_analysis:
                self._analysis()

            # Show timing statistics if debug level is activated
            if logger.isEnabledFor(logging.DEBUG):
                final_time = time.time()
                elapsed_time = final_time - initial_time
                estimated_time_remaining = (final_time - run_start_time) / (self.iteration - run_start_iteration) * (iteration_limit - self.iteration)
                estimated_total_time = (final_time - run_start_time) / (self.iteration - run_start_iteration) * (iteration_limit)
                estimated_finish_time = final_time + estimated_time_remaining
                logger.debug("Iteration took %.3f s." % elapsed_time)
                logger.debug("Estimated completion in %s, at %s (consuming total wall clock time %s)." % (str(datetime.timedelta(seconds=estimated_time_remaining)), time.ctime(estimated_finish_time), str(datetime.timedelta(seconds=estimated_total_time))))

            # Perform sanity checks to see if we should terminate here.
            self._run_sanity_checks()

        # Clean up and close storage files.
        self._finalize()

    # -------------------------------------------------------------------------
    # Internal-usage: Initialization.
    # -------------------------------------------------------------------------

    @staticmethod
    def _does_file_exist(file_path):
        """Check if there is a file at the given path."""
        return os.path.exists(file_path) and os.path.getsize(file_path) > 0

    # -------------------------------------------------------------------------
    # Internal-usage: Storage utilities.
    # -------------------------------------------------------------------------

    @mpi.on_single_node(rank=0, broadcast_result=False, sync_nodes=True)
    def _initialize_reporter(self, storage, metadata):
        """Initialize the reporter and store initial information.

        This is executed only on MPI node 0 and it is blocking. This is to
        avoid the case where the other nodes skip ahead and try to read
        from a file that hasn't been created yet.

        """
        self._reporter = Reporter(storage, mode='w')
        self._reporter.write_thermodynamic_states(self._thermodynamic_states)
        self._reporter.write_mcmc_moves(self._mcmc_moves)

        # Store run metadata and ReplicaExchange options.
        self._store_options()
        self._store_metadata(metadata)

        # Store initial conditions. This forces the storage to be synchronized.
        self._report_iteration()

    @mpi.on_single_node(rank=0, broadcast_result=False, sync_nodes=False)
    @mpi.delayed_termination
    @mmtools.utils.with_timer('Writing iteration information to storage')
    def _report_iteration(self):
        """Store positions, states, and energies of current iteration.

        This is executed only on MPI node 0 and it's not blocking. The
        termination is delayed so that the file is not written only with
        partial data if the program gets interrupted.

        """
        self._reporter.write_sampler_states(self._sampler_states, self._iteration)
        self._reporter.write_replica_thermodynamic_states(self._replica_thermodynamic_states, self._iteration)
        self._reporter.write_energies(self._u_kl, self._iteration)
        self._reporter.write_mixing_statistics(self._n_accepted_matrix, self._n_proposed_matrix, self._iteration)
        self._reporter.write_timestamp(self._iteration)
        self._reporter.sync()

    def _store_options(self):
        """Store __init__ parameters in storage file."""
        logger.debug("Storing general ReplicaExchange options...")

        # Inspect __init__ parameters to store.
        parameter_names, _, _, defaults = inspect.getargspec(self.__init__)

        # Retrieve and store options.
        options_to_store = {parameter_name: getattr(self, '_' + parameter_name)
                            for parameter_name in parameter_names[-len(defaults):]}
        # We store the MCMCMoves separately.
        options_to_store.pop('mcmc_moves')
        self._reporter.write_dict('options', options_to_store)

    def _store_metadata(self, metadata):
        """Store metadata."""
        # Handle default behavior and add default simulation title.
        default_title = ('Replica-exchange simulation created using ReplicaExchange class '
                         'of yank.repex.py on {}'.format(time.asctime(time.localtime())))
        if metadata is None:
            metadata = dict(title=default_title)
        elif 'title' not in metadata:
            metadata['title'] = default_title
        self._reporter.write_dict('metadata', metadata)

    def _initialize_resume(self):
        """
        Initialize the simulation, and bind to a storage file.

        """

        if self._initialized:
            raise RuntimeError("Simulation has already been initialized.")

        # Extract a representative system.
        representative_system = self.states[0].system

        # Turn off verbosity if not master node.
        if self.mpicomm:
            # Have each node report that it is initialized.
            # TODO this doesn't work on worker nodes since they report only warning entries and higher
            logger.debug("Initialized node %d / %d" % (self.mpicomm.rank, self.mpicomm.size))

        # Display papers to be cited.
        if utils.is_terminal_verbose():
            self._display_citations()

        # Determine number of alchemical states.
        self.nstates = len(self.states)

        # Determine number of atoms in systems.
        self.natoms = representative_system.getNumParticles()

        # Allocate storage.
        self.replica_positions = list() # replica_positions[i] is the configuration currently held in replica i
        self.replica_box_vectors = list() # replica_box_vectors[i] is the set of box vectors currently held in replica i
        self.replica_states     = np.zeros([self.nstates], np.int32) # replica_states[i] is the state that replica i is currently at
        self.u_kl               = np.zeros([self.nstates, self.nstates], np.float64)
        self.swap_Pij_accepted  = np.zeros([self.nstates, self.nstates], np.float64)
        self.Nij_proposed       = np.zeros([self.nstates,self.nstates], np.int64) # Nij_proposed[i][j] is the number of swaps proposed between states i and j, prior of 1
        self.Nij_accepted       = np.zeros([self.nstates,self.nstates], np.int64) # Nij_proposed[i][j] is the number of swaps proposed between states i and j, prior of 1

        # Distribute coordinate information to replicas in a round-robin fashion, making a deep copy.
        if not self._resume:
            self.replica_positions = [ copy.deepcopy(self.provided_positions[replica_index % len(self.provided_positions)]) for replica_index in range(self.nstates) ]

        # Assign default box vectors.
        self.replica_box_vectors = list()
        for state in self.states:
            [a,b,c] = state.system.getDefaultPeriodicBoxVectors()
            box_vectors = unit.Quantity(np.zeros([3,3], np.float32), unit.nanometers)
            box_vectors[0,:] = a
            box_vectors[1,:] = b
            box_vectors[2,:] = c
            self.replica_box_vectors.append(box_vectors)

        # Assign initial replica states.
        for replica_index in range(self.nstates):
            self.replica_states[replica_index] = replica_index

        # Check to make sure NetCDF file exists.
        if not os.path.exists(self.store_filename):
            raise Exception("Store file %s does not exist." % self.store_filename)

        # Open NetCDF file for reading
        logger.debug("Reading NetCDF file '%s'..." % self.store_filename)
        ncfile = netcdf.Dataset(self.store_filename, 'r')

        # Resume from NetCDF file.
        self._resume_from_netcdf(ncfile)

        # Close NetCDF file.
        ncfile.close()

        if (self.mpicomm is None) or (self.mpicomm.rank == 0):
            # Reopen NetCDF file for appending, and maintain handle.
            self.ncfile = netcdf.Dataset(self.store_filename, 'a')
        else:
            self.ncfile = None

        # On first iteration, we need to do some initialization.
        if self.iteration == 0:
            # Perform sanity checks to see if we should terminate here.
            self._run_sanity_checks()

            # Minimize and equilibrate all replicas.
            self._minimize_and_equilibrate()

            # Compute energies of all alchemical replicas
            self._compute_energies()

            # Show energies.
            if self.show_energies:
                self._show_energies()

            # Re-store initial state.
            # TODO: Sort this logic out.
            #self.ncfile = ncfile
            #self._write_iteration_netcdf()
            #self.ncfile = None

        # Run sanity checks.
        # TODO: Refine this.
        self._run_sanity_checks()
        #self._compute_energies() # recompute energies?
        #self._run_sanity_checks()

        # We will work on the next iteration.
        self.iteration += 1

        # Show energies.
        if self.show_energies:
            self._show_energies()

        # Analysis object starts off empty.
        self.analysis = None

        # Signal that the class has been initialized.
        self._initialized = True

        return

    def _display_citations(self):
        """
        Display papers to be cited.

        TODO:

        * Add original citations for various replica-exchange schemes.
        * Show subset of OpenMM citations based on what features are being used.

        """

        openmm_citations = """\
        Friedrichs MS, Eastman P, Vaidyanathan V, Houston M, LeGrand S, Beberg AL, Ensign DL, Bruns CM, and Pande VS. Accelerating molecular dynamic simulations on graphics processing unit. J. Comput. Chem. 30:864, 2009. DOI: 10.1002/jcc.21209
        Eastman P and Pande VS. OpenMM: A hardware-independent framework for molecular simulations. Comput. Sci. Eng. 12:34, 2010. DOI: 10.1109/MCSE.2010.27
        Eastman P and Pande VS. Efficient nonbonded interactions for molecular dynamics on a graphics processing unit. J. Comput. Chem. 31:1268, 2010. DOI: 10.1002/jcc.21413
        Eastman P and Pande VS. Constant constraint matrix approximation: A robust, parallelizable constraint method for molecular simulations. J. Chem. Theor. Comput. 6:434, 2010. DOI: 10.1021/ct900463w"""

        gibbs_citations = """\
        Chodera JD and Shirts MR. Replica exchange and expanded ensemble simulations as Gibbs sampling: Simple improvements for enhanced mixing. J. Chem. Phys., 135:194110, 2011. DOI:10.1063/1.3660669"""

        mbar_citations = """\
        Shirts MR and Chodera JD. Statistically optimal analysis of samples from multiple equilibrium states. J. Chem. Phys. 129:124105, 2008. DOI: 10.1063/1.2978177"""

        print("Please cite the following:")
        print("")
        print(openmm_citations)
        if self._replica_mixing_scheme == 'swap-all':
            print(gibbs_citations)
        if self._online_analysis:
            print(mbar_citations)

        return

    def _create_context(self, system, integrator):
        """
        Shortcut to handle creation of a context with or without user-selected
        platform.

        Parameters
        ----------
        system : simtk.openmm.System
           The system associated to the context.
        integrator : simtk.openmm.Integrator
           The integrator to use for Context creation.

        Returns
        -------
        context : simtk.openmm.Context
           The created OpenMM Context object.

        """
        if self.platform is None:
            return self.mm.Context(system, integrator)
        else:
            return self.mm.Context(system, integrator, self.platform)

    def _propagate_replica(self, replica_index):
        """
        Propagate the replica corresponding to the specified replica index.
        Caching is used.

        ARGUMENTS

        replica_index (int) - the replica to propagate

        RETURNS

        elapsed_time (float) - time (in seconds) to propagate replica

        """

        start_time = time.time()

        # Retrieve state.
        state_index = self.replica_states[replica_index] # index of thermodynamic state that current replica is assigned to
        state = self.states[state_index] # thermodynamic state

        # If temperature and pressure are specified, make sure MonteCarloBarostat is attached.
        if state.temperature and state.pressure:
            forces = { state.system.getForce(index).__class__.__name__ : state.system.getForce(index) for index in range(state.system.getNumForces()) }

            if 'MonteCarloAnisotropicBarostat' in forces:
                raise Exception('MonteCarloAnisotropicBarostat is unsupported.')

            if 'MonteCarloBarostat' in forces:
                barostat = forces['MonteCarloBarostat']
                # Set temperature and pressure.
                try:
                    barostat.setDefaultTemperature(state.temperature)
                except AttributeError:  # versions previous to OpenMM0.8
                    barostat.setTemperature(state.temperature)
                barostat.setDefaultPressure(state.pressure)
                barostat.setRandomNumberSeed(int(np.random.randint(0, MAX_SEED)))
            else:
                # Create barostat and add it to the system if it doesn't have one already.
                barostat = openmm.MonteCarloBarostat(state.pressure, state.temperature)
                barostat.setRandomNumberSeed(int(np.random.randint(0, MAX_SEED)))
                state.system.addForce(barostat)

        # Create Context and integrator.
        integrator = openmm.LangevinIntegrator(state.temperature, self.collision_rate, self.timestep)
        integrator.setRandomNumberSeed(int(np.random.randint(0, MAX_SEED)))
        context = self._create_context(state.system, integrator)

        # Set box vectors.
        box_vectors = self.replica_box_vectors[replica_index]
        context.setPeriodicBoxVectors(box_vectors[0,:], box_vectors[1,:], box_vectors[2,:])
        # Set positions.
        positions = self.replica_positions[replica_index]
        context.setPositions(positions)
        setpositions_end_time = time.time()
        # Assign Maxwell-Boltzmann velocities.
        context.setVelocitiesToTemperature(state.temperature, int(np.random.randint(0, MAX_SEED)))
        setvelocities_end_time = time.time()
        # Run dynamics.
        integrator.step(self.nsteps_per_iteration)
        integrator_end_time = time.time()
        # Store final positions
        getstate_start_time = time.time()
        openmm_state = context.getState(getPositions=True, enforcePeriodicBox=state.system.usesPeriodicBoundaryConditions())
        getstate_end_time = time.time()
        self.replica_positions[replica_index] = openmm_state.getPositions(asNumpy=True)
        # Store box vectors.
        self.replica_box_vectors[replica_index] = openmm_state.getPeriodicBoxVectors(asNumpy=True)

        # Clean up.
        del context, integrator

        # Compute timing.
        end_time = time.time()
        elapsed_time = end_time - start_time
        positions_elapsed_time = setpositions_end_time - start_time
        velocities_elapsed_time = setvelocities_end_time - setpositions_end_time
        integrator_elapsed_time = integrator_end_time - setvelocities_end_time
        getstate_elapsed_time = getstate_end_time - integrator_end_time
        logger.debug("Replica %d/%d: integrator elapsed time %.3f s (positions %.3f s | velocities %.3f s | integrate+getstate %.3f s)." % (replica_index, self.nreplicas, elapsed_time, positions_elapsed_time, velocities_elapsed_time, integrator_elapsed_time+getstate_elapsed_time))

        return elapsed_time

    def _propagate_replicas_mpi(self):
        """
        Propagate all replicas using MPI communicator.

        It is presumed all nodes have the correct configurations in the correct replica slots, but that state indices may be unsynchronized.

        TODO

        * Move synchronization of state information to mix_replicas?
        * Broadcast from root node only?

        """

        # Propagate all replicas.
        logger.debug("Propagating all replicas for %.3f ps..." % (self.nsteps_per_iteration * self.timestep / unit.picoseconds))

        # Run just this node's share of states.
        logger.debug("Running trajectories...")
        start_time = time.time()
        # replica_lookup = { self.replica_states[replica_index] : replica_index for replica_index in range(self.nstates) } # replica_lookup[state_index] is the replica index currently at state 'state_index' # requires Python 2.7 features
        replica_lookup = dict( (self.replica_states[replica_index], replica_index) for replica_index in range(self.nstates) ) # replica_lookup[state_index] is the replica index currently at state 'state_index' # Python 2.6 compatible
        replica_indices = [ replica_lookup[state_index] for state_index in range(self.mpicomm.rank, self.nstates, self.mpicomm.size) ] # list of replica indices for this node to propagate
        for replica_index in replica_indices:
            logger.debug("Node %3d/%3d propagating replica %3d state %3d..." % (self.mpicomm.rank, self.mpicomm.size, replica_index, self.replica_states[replica_index]))
            self._propagate_replica(replica_index)
        end_time = time.time()
        elapsed_time = end_time - start_time
        # Collect elapsed time.
        node_elapsed_times = self.mpicomm.gather(elapsed_time, root=0) # barrier
        if self.mpicomm.rank == 0 and logger.isEnabledFor(logging.DEBUG):
            node_elapsed_times = np.array(node_elapsed_times)
            end_time = time.time()
            elapsed_time = end_time - start_time
            barrier_wait_times = elapsed_time - node_elapsed_times
            logger.debug("Running trajectories: elapsed time %.3f s (barrier time min %.3f s | max %.3f s | avg %.3f s)" % (elapsed_time, barrier_wait_times.min(), barrier_wait_times.max(), barrier_wait_times.mean()))
            logger.debug("Total time spent waiting for GPU: %.3f s" % (node_elapsed_times.sum()))

        # Send final configurations and box vectors back to all nodes.
        logger.debug("Synchronizing trajectories...")
        start_time = time.time()
        replica_indices_gather = self.mpicomm.allgather(replica_indices)
        replica_positions_gather = self.mpicomm.allgather([ self.replica_positions[replica_index] for replica_index in replica_indices ])
        replica_box_vectors_gather = self.mpicomm.allgather([ self.replica_box_vectors[replica_index] for replica_index in replica_indices ])
        for (source, replica_indices) in enumerate(replica_indices_gather):
            for (index, replica_index) in enumerate(replica_indices):
                self.replica_positions[replica_index] = replica_positions_gather[source][index]
                self.replica_box_vectors[replica_index] = replica_box_vectors_gather[source][index]
        end_time = time.time()
        logger.debug("Synchronizing configurations and box vectors: elapsed time %.3f s" % (end_time - start_time))

        return

    def _propagate_replicas_serial(self):
        """
        Propagate all replicas using serial execution.

        """

        # Propagate all replicas.
        logger.debug("Propagating all replicas for %.3f ps..." % (self.nsteps_per_iteration * self.timestep / unit.picoseconds))
        for replica_index in range(self.nstates):
            self._propagate_replica(replica_index)

        return

    def _propagate_replicas(self):
        """
        Propagate all replicas.

        TODO

        * Report on efficiency of dyanmics (fraction of time wasted to overhead).

        """
        start_time = time.time()

        if self.mpicomm:
            self._propagate_replicas_mpi()
        else:
            self._propagate_replicas_serial()

        end_time = time.time()
        elapsed_time = end_time - start_time
        time_per_replica = elapsed_time / float(self.nstates)
        ns_per_day = self.timestep * self.nsteps_per_iteration / time_per_replica * 24*60*60 / unit.nanoseconds
        logger.debug("Time to propagate all replicas: %.3f s (%.3f per replica, %.3f ns/day)." % (elapsed_time, time_per_replica, ns_per_day))

        return

    def _minimize_replica(self, replica_id, minimize_tolerance, minimize_max_iterations):
        """Minimize the specified replica."""
        # Retrieve thermodynamic and sampler states.
        thermodynamic_state_id = self._replica_thermodynamic_states[replica_id]
        thermodynamic_state = self._thermodynamic_states[thermodynamic_state_id]
        sampler_state = self._sampler_states[replica_id]

        # Retrieve a context. Any Integrator works.
        context, integrator = mmtools.cache.global_context_cache.get_context(thermodynamic_state)

        # Set initial positions and box vectors.
        sampler_state.apply_to_context(context)

        # Compute the initial energy of the system for logging.
        initial_energy = thermodynamic_state.reduced_potential(context)
        logger.debug('Replica {}/{}: initial energy {:8.3f}kT'.format(
            replica_id, self.n_replicas, initial_energy))

        # Minimize energy.
        openmm.LocalEnergyMinimizer.minimize(context, minimize_tolerance, minimize_max_iterations)

        # Get the minimized positions.
        sampler_state.update_from_context(context)

        # Compute the final energy of the system for logging.
        final_energy = thermodynamic_state.reduced_potential(sampler_state)
        logger.debug('Replica {}/{}: final energy {:8.3f}kT'.format(
            replica_id, self.n_replicas, final_energy))

        # Return minimized positions.
        return sampler_state.positions

    def _minimize_and_equilibrate(self):
        """
        Minimize and equilibrate all replicas.

        """

        # Minimize
        if self.minimize:
            logger.debug("Minimizing all replicas...")

            if self.mpicomm:
                # MPI implementation.
                logger.debug("MPI implementation.")
                # Minimize this node's share of replicas.
                start_time = time.time()
                for replica_index in range(self.mpicomm.rank, self.nstates, self.mpicomm.size):
                    logger.debug("node %d / %d : minimizing replica %d / %d" % (self.mpicomm.rank, self.mpicomm.size, replica_index, self.nstates))
                    self._minimize_replica(replica_index)
                end_time = time.time()
                debug_msg = 'Node {}/{}: MPI barrier'.format(self.mpicomm.rank, self.mpicomm.size)
                logger.debug(debug_msg + ' - waiting for the minimization to be completed.')
                self.mpicomm.barrier()
                logger.debug("Running trajectories: elapsed time %.3f s" % (end_time - start_time))

                # Send final configurations and box vectors back to all nodes.
                logger.debug("Synchronizing trajectories...")
                replica_positions_gather = self.mpicomm.allgather(self.replica_positions[self.mpicomm.rank:self.nstates:self.mpicomm.size])
                replica_box_vectors_gather = self.mpicomm.allgather(self.replica_box_vectors[self.mpicomm.rank:self.nstates:self.mpicomm.size])
                for replica_index in range(self.nstates):
                    source = replica_index % self.mpicomm.size # node with trajectory data
                    index = replica_index // self.mpicomm.size # index within trajectory batch
                    self.replica_positions[replica_index] = replica_positions_gather[source][index]
                    self.replica_box_vectors[replica_index] = replica_box_vectors_gather[source][index]
                logger.debug("Synchronizing configurations and box vectors: elapsed time %.3f s" % (end_time - start_time))

            else:
                # Serial implementation.
                logger.debug("Serial implementation.")
                for replica_index in range(self.nstates):
                    logger.debug("minimizing replica %d / %d" % (replica_index, self.nstates))
                    self._minimize_replica(replica_index)

        # Equilibrate: temporarily set timestep to equilibration timestep
        production_timestep = self.timestep
        self.timestep = self.equilibration_timestep
        for iteration in range(self.number_of_equilibration_iterations):
            logger.debug("equilibration iteration %d / %d" % (iteration, self.number_of_equilibration_iterations))
            self._propagate_replicas()
        self.timestep = production_timestep

        return

    @mmtools.utils.with_timer('Computing energy matrix')
    def _compute_energies(self):
        """Compute energies of all replicas at all states."""

        # Distribute energy computation across nodes. Only node 0 receives
        # all the energies since it needs to store them and mix states.
        new_u_kl, replica_ids = mpi.distribute(self._compute_replica_energies, range(self.n_replicas),
                                               send_results_to=0)

        # Update u_kl matrix. Non-0 nodes update only the energies
        # computed by this replica.
        for replica_id in replica_ids:
            self._u_kl[replica_id] = new_u_kl[replica_id]

    def _compute_replica_energies(self, replica_id):
        """Compute the energy for the replica in every ThermodynamicState."""
        # Initialize replica energies for each thermodynamic state.
        replica_energies = np.zeros(self.n_replicas)

        # Retrieve sampler states associated to this replica.
        sampler_state = self._sampler_states[replica_id]

        for i, thermodynamic_state in enumerate(self._thermodynamic_states):
            # Get the context, any Integrator works.
            context, integrator = mmtools.cache.global_context_cache.get_context(thermodynamic_state)

            # Update positions and box vectors.
            sampler_state.apply_to_context(context)

            # Compute energy.
            replica_energies[i] = thermodynamic_state.reduced_potential(context)

        # Return the new energies.
        return replica_energies

    def _mix_all_replicas(self):
        """
        Attempt exchanges between all replicas to enhance mixing.

        TODO

        * Adjust nswap_attempts based on how many we can afford to do and not have mixing take a substantial fraction of iteration time.

        """

        # Determine number of swaps to attempt to ensure thorough mixing.
        # TODO: Replace this with analytical result computed to guarantee sufficient mixing.
        nswap_attempts = self.nstates**5 # number of swaps to attempt (ideal, but too slow!)
        nswap_attempts = self.nstates**3 # best compromise for pure Python?

        logger.debug("Will attempt to swap all pairs of replicas, using a total of %d attempts." % nswap_attempts)

        # Attempt swaps to mix replicas.
        for swap_attempt in range(nswap_attempts):
            # Choose replicas to attempt to swap.
            i = np.random.randint(self.nstates) # Choose replica i uniformly from set of replicas.
            j = np.random.randint(self.nstates) # Choose replica j uniformly from set of replicas.

            # Determine which states these resplicas correspond to.
            istate = self.replica_states[i] # state in replica slot i
            jstate = self.replica_states[j] # state in replica slot j

            # Reject swap attempt if any energies are nan.
            if (np.isnan(self.u_kl[i,jstate]) or np.isnan(self.u_kl[j,istate]) or np.isnan(self.u_kl[i,istate]) or np.isnan(self.u_kl[j,jstate])):
                continue

            # Compute log probability of swap.
            log_P_accept = - (self.u_kl[i,jstate] + self.u_kl[j,istate]) + (self.u_kl[i,istate] + self.u_kl[j,jstate])

            #print("replica (%3d,%3d) states (%3d,%3d) energies (%8.1f,%8.1f) %8.1f -> (%8.1f,%8.1f) %8.1f : log_P_accept %8.1f" % (i,j,istate,jstate,self.u_kl[i,istate],self.u_kl[j,jstate],self.u_kl[i,istate]+self.u_kl[j,jstate],self.u_kl[i,jstate],self.u_kl[j,istate],self.u_kl[i,jstate]+self.u_kl[j,istate],log_P_accept))

            # Record that this move has been proposed.
            self.Nij_proposed[istate,jstate] += 1
            self.Nij_proposed[jstate,istate] += 1

            # Accept or reject.
            if (log_P_accept >= 0.0 or (np.random.rand() < math.exp(log_P_accept))):
                # Swap states in replica slots i and j.
                (self.replica_states[i], self.replica_states[j]) = (self.replica_states[j], self.replica_states[i])
                # Accumulate statistics
                self.Nij_accepted[istate,jstate] += 1
                self.Nij_accepted[jstate,istate] += 1

        return

    def _mix_all_replicas_cython(self):
        """
        Attempt to exchange all replicas to enhance mixing, calling code written in Cython.
        """

        from .mixing._mix_replicas import _mix_replicas_cython

        replica_states = md.utils.ensure_type(self.replica_states, np.int64, 1, "Replica States")
        u_kl = md.utils.ensure_type(self.u_kl, np.float64, 2, "Reduced Potentials")
        Nij_proposed = md.utils.ensure_type(self.Nij_proposed, np.int64, 2, "Nij Proposed")
        Nij_accepted = md.utils.ensure_type(self.Nij_accepted, np.int64, 2, "Nij accepted")
        _mix_replicas_cython(self.nstates**4, self.nstates, replica_states, u_kl, Nij_proposed, Nij_accepted)

        #replica_states = np.array(self.replica_states, np.int64)
        #u_kl = np.array(self.u_kl, np.float64)
        #Nij_proposed = np.array(self.Nij_proposed, np.int64)
        #Nij_accepted = np.array(self.Nij_accepted, np.int64)
        #_mix_replicas._mix_replicas_cython(self.nstates**4, self.nstates, replica_states, u_kl, Nij_proposed, Nij_accepted)

        self.replica_states = replica_states
        self.Nij_proposed = Nij_proposed
        self.Nij_accepted = Nij_accepted

    def _mix_neighboring_replicas(self):
        """
        Attempt exchanges between neighboring replicas only.

        """

        logger.debug("Will attempt to swap only neighboring replicas.")

        # Attempt swaps of pairs of replicas using traditional scheme (e.g. [0,1], [2,3], ...)
        offset = np.random.randint(2) # offset is 0 or 1
        for istate in range(offset, self.nstates-1, 2):
            jstate = istate + 1 # second state to attempt to swap with i

            # Determine which replicas these states correspond to.
            i = None
            j = None
            for index in range(self.nstates):
                if self.replica_states[index] == istate: i = index
                if self.replica_states[index] == jstate: j = index

            # Reject swap attempt if any energies are nan.
            if (np.isnan(self.u_kl[i,jstate]) or np.isnan(self.u_kl[j,istate]) or np.isnan(self.u_kl[i,istate]) or np.isnan(self.u_kl[j,jstate])):
                continue

            # Compute log probability of swap.
            log_P_accept = - (self.u_kl[i,jstate] + self.u_kl[j,istate]) + (self.u_kl[i,istate] + self.u_kl[j,jstate])

            #print("replica (%3d,%3d) states (%3d,%3d) energies (%8.1f,%8.1f) %8.1f -> (%8.1f,%8.1f) %8.1f : log_P_accept %8.1f" % (i,j,istate,jstate,self.u_kl[i,istate],self.u_kl[j,jstate],self.u_kl[i,istate]+self.u_kl[j,jstate],self.u_kl[i,jstate],self.u_kl[j,istate],self.u_kl[i,jstate]+self.u_kl[j,istate],log_P_accept))

            # Record that this move has been proposed.
            self.Nij_proposed[istate,jstate] += 1
            self.Nij_proposed[jstate,istate] += 1

            # Accept or reject.
            if (log_P_accept >= 0.0 or (np.random.rand() < math.exp(log_P_accept))):
                # Swap states in replica slots i and j.
                (self.replica_states[i], self.replica_states[j]) = (self.replica_states[j], self.replica_states[i])
                # Accumulate statistics
                self.Nij_accepted[istate,jstate] += 1
                self.Nij_accepted[jstate,istate] += 1

        return

    def _mix_replicas(self):
        """
        Attempt to swap replicas according to user-specified scheme.

        """

        if (self.mpicomm) and (self.mpicomm.rank != 0):
            # Non-root nodes receive state information.
            logger.debug('Node {}/{}: MPI bcast - sharing replica_states'.format(
                    self.mpicomm.rank, self.mpicomm.size))
            self.replica_states = self.mpicomm.bcast(self.replica_states, root=0)
            return

        logger.debug("Mixing replicas...")

        # Reset storage to keep track of swap attempts this iteration.
        self.Nij_proposed[:,:] = 0
        self.Nij_accepted[:,:] = 0

        # Perform swap attempts according to requested scheme.
        start_time = time.time()
        if self.replica_mixing_scheme == 'swap-neighbors':
            self._mix_neighboring_replicas()
        elif self.replica_mixing_scheme == 'swap-all':
            # Try to use cython-accelerated mixing code if possible, otherwise fall back to Python-accelerated code.
            try:
                self._mix_all_replicas_cython()
            except ValueError as e:
                logger.warning(e.message)
                self._mix_all_replicas()
        elif self.replica_mixing_scheme == 'none':
            # Don't mix replicas.
            pass
        else:
            raise ParameterException("Replica mixing scheme '%s' unknown.  Choose valid 'replica_mixing_scheme' parameter." % self.replica_mixing_scheme)
        end_time = time.time()

        # Determine fraction of swaps accepted this iteration.
        nswaps_attempted = self.Nij_proposed.sum()
        nswaps_accepted = self.Nij_accepted.sum()
        swap_fraction_accepted = 0.0
        if (nswaps_attempted > 0): swap_fraction_accepted = float(nswaps_accepted) / float(nswaps_attempted);
        logger.debug("Accepted %d / %d attempted swaps (%.1f %%)" % (nswaps_accepted, nswaps_attempted, swap_fraction_accepted * 100.0))

        # Estimate cumulative transition probabilities between all states.
        # TODO don't read ncfile every time, store cumulative
        Nij_accepted = self.ncfile.variables['accepted'][:,:,:].sum(0) + self.Nij_accepted
        Nij_proposed = self.ncfile.variables['proposed'][:,:,:].sum(0) + self.Nij_proposed
        swap_Pij_accepted = np.zeros([self.nstates,self.nstates], np.float64)
        for istate in range(self.nstates):
            Ni = Nij_proposed[istate,:].sum()
            if (Ni == 0):
                swap_Pij_accepted[istate,istate] = 1.0
            else:
                swap_Pij_accepted[istate,istate] = 1.0 - float(Nij_accepted[istate,:].sum() - Nij_accepted[istate,istate]) / float(Ni)
                for jstate in range(self.nstates):
                    if istate != jstate:
                        swap_Pij_accepted[istate,jstate] = float(Nij_accepted[istate,jstate]) / float(Ni)

        if self.mpicomm:
            # Root node will share state information with all replicas.
            logger.debug('Node {}/{}: MPI bcast - sharing replica_states'.format(
                    self.mpicomm.rank, self.mpicomm.size))
            self.replica_states = self.mpicomm.bcast(self.replica_states, root=0)

        # Report on mixing.
        logger.debug("Mixing of replicas took %.3f s" % (end_time - start_time))

        return

    def _accumulate_mixing_statistics(self):
        """Return the mixing transition matrix Tij."""
        try:
            return self._accumulate_mixing_statistics_update()
        except AttributeError:
            pass
        except ValueError:
            logger.info("Inconsistent transition count matrix detected, recalculating from scratch.")

        return self._accumulate_mixing_statistics_full()

    def _accumulate_mixing_statistics_full(self):
        """Compute statistics of transitions iterating over all iterations of repex."""
        states = self.ncfile.variables['states']
        self._Nij = np.zeros([self.nstates, self.nstates], np.float64)
        for iteration in range(states.shape[0]-1):
            for ireplica in range(self.nstates):
                istate = states[iteration, ireplica]
                jstate = states[iteration + 1, ireplica]
                self._Nij[istate, jstate] += 0.5
                self._Nij[jstate, istate] += 0.5

        Tij = np.zeros([self.nstates, self.nstates], np.float64)
        for istate in range(self.nstates):
            Tij[istate] = self._Nij[istate] / self._Nij[istate].sum()

        return Tij

    def _accumulate_mixing_statistics_update(self):
        """Compute statistics of transitions updating Nij of last iteration of repex."""

        states = self.ncfile.variables['states']
        if self._Nij.sum() != (states.shape[0] - 2) * self.nstates:  # n_iter - 2 = (n_iter - 1) - 1.  Meaning that you have exactly one new iteration to process.
            raise(ValueError("Inconsistent transition count matrix detected.  Perhaps you tried updating twice in a row?"))

        for ireplica in range(self.nstates):
            istate = states[self.iteration-2, ireplica]
            jstate = states[self.iteration-1, ireplica]
            self._Nij[istate, jstate] += 0.5
            self._Nij[jstate, istate] += 0.5

        Tij = np.zeros([self.nstates, self.nstates], np.float64)
        for istate in range(self.nstates):
            Tij[istate] = self._Nij[istate] / self._Nij[istate].sum()

        return Tij

    def _show_mixing_statistics(self):

        if self.iteration < 2:
            return
        if self.mpicomm and self.mpicomm.rank != 0:
            return  # only root node have access to ncfile
        if not logger.isEnabledFor(logging.DEBUG):
            return

        Tij = self._accumulate_mixing_statistics()

        # Print observed transition probabilities.
        PRINT_CUTOFF = 0.001 # Cutoff for displaying fraction of accepted swaps.
        logger.debug("Cumulative symmetrized state mixing transition matrix:")
        str_row = "%6s" % ""
        for jstate in range(self.nstates):
            str_row += "%6d" % jstate
        logger.debug(str_row)
        for istate in range(self.nstates):
            str_row = "%-6d" % istate
            for jstate in range(self.nstates):
                P = Tij[istate,jstate]
                if (P >= PRINT_CUTOFF):
                    str_row += "%6.3f" % P
                else:
                    str_row += "%6s" % ""
            logger.debug(str_row)

        # Estimate second eigenvalue and equilibration time.
        mu = np.linalg.eigvals(Tij)
        mu = -np.sort(-mu) # sort in descending order
        if (mu[1] >= 1):
            logger.debug("Perron eigenvalue is unity; Markov chain is decomposable.")
        else:
            logger.debug("Perron eigenvalue is %9.5f; state equilibration timescale is ~ %.1f iterations" % (mu[1], 1.0 / (1.0 - mu[1])))

    def _run_sanity_checks(self):
        """
        Run some checks on current state information to see if something has gone wrong that precludes continuation.

        """

        abort = False

        # Check positions.
        for replica_index in range(self.nreplicas):
            positions = self.replica_positions[replica_index]
            x = positions / unit.nanometers
            if np.any(np.isnan(x)):
                logger.warning("nan encountered in replica %d positions." % replica_index)
                abort = True

        # Check energies.
        for replica_index in range(self.nreplicas):
            if np.any(np.isnan(self.u_kl[replica_index,:])):
                logger.warning("nan encountered in u_kl state energies for replica %d" % replica_index)
                abort = True

        if abort:
            if self.mpicomm:
                self.mpicomm.Abort()
            else:
                raise Exception("Aborting.")

        return

    def _show_energies(self):
        """
        Show energies (in units of kT) for all replicas at all states.

        """

        if not logger.isEnabledFor(logging.DEBUG):
            return

        # print header
        str_row = "%-24s %16s" % ("reduced potential (kT)", "current state")
        for state_index in range(self.nstates):
            str_row += " state %3d" % state_index
        logger.debug(str_row)

        # print energies in kT
        for replica_index in range(self.nstates):
            str_row = "replica %-16d %16d" % (replica_index, self.replica_states[replica_index])
            for state_index in range(self.nstates):
                u = self.u_kl[replica_index,state_index]
                if (u > 1e6):
                    str_row += "%10.3e" % u
                else:
                    str_row += "%10.1f" % u
            logger.debug(str_row)

        return


#=============================================================================================
# Parallel tempering
#=============================================================================================

class ParallelTempering(ReplicaExchange):
    """
    Parallel tempering simulation facility.

    DESCRIPTION

    This class provides a facility for parallel tempering simulations.  It is a subclass of ReplicaExchange, but provides
    various convenience methods and efficiency improvements for parallel tempering simulations, so should be preferred for
    this type of simulation.  In particular, the System only need be specified once, while the temperatures (or a temperature
    range) is used to automatically build a set of ThermodynamicState objects for replica-exchange.  Efficiency improvements
    make use of the fact that the reduced potentials are linear in inverse temperature.

    EXAMPLES

    Parallel tempering of alanine dipeptide in implicit solvent.

    >>> # Create alanine dipeptide test system.
    >>> from openmmtools import testsystems
    >>> testsystem = testsystems.AlanineDipeptideImplicit()
    >>> [system, positions] = [testsystem.system, testsystem.positions]
    >>> # Create temporary file for storing output.
    >>> import tempfile
    >>> file = tempfile.NamedTemporaryFile() # temporary file for testing
    >>> store_filename = file.name
    >>> # Initialize parallel tempering on an exponentially-spaced scale
    >>> Tmin = 298.0 * unit.kelvin
    >>> Tmax = 600.0 * unit.kelvin
    >>> nreplicas = 3
    >>> simulation = ParallelTempering(store_filename)
    >>> simulation.create(system, positions, Tmin=Tmin, Tmax=Tmax, ntemps=nreplicas)
    >>> simulation.number_of_iterations = 2 # set the simulation to only run 10 iterations
    >>> simulation.timestep = 2.0 * unit.femtoseconds # set the timestep for integration
    >>> simulation.minimize = False
    >>> simulation.nsteps_per_iteration = 50 # run 50 timesteps per iteration
    >>> # Run simulation.
    >>> simulation.run() # run the simulation

    Parallel tempering of alanine dipeptide in explicit solvent at 1 atm.

    >>> # Create alanine dipeptide system
    >>> from openmmtools import testsystems
    >>> testsystem = testsystems.AlanineDipeptideExplicit()
    >>> [system, positions] = [testsystem.system, testsystem.positions]
    >>> # Add Monte Carlo barsostat to system (must be same pressure as simulation).
    >>> import simtk.openmm as openmm
    >>> pressure = 1.0 * unit.atmosphere
    >>> # Create temporary file for storing output.
    >>> import tempfile
    >>> file = tempfile.NamedTemporaryFile() # temporary file for testing
    >>> store_filename = file.name
    >>> # Initialize parallel tempering on an exponentially-spaced scale
    >>> Tmin = 298.0 * unit.kelvin
    >>> Tmax = 600.0 * unit.kelvin
    >>> nreplicas = 3
    >>> simulation = ParallelTempering(store_filename)
    >>> simulation.create(system, positions, Tmin=Tmin, Tmax=Tmax, pressure=pressure, ntemps=nreplicas)
    >>> simulation.number_of_iterations = 2 # set the simulation to only run 10 iterations
    >>> simulation.timestep = 2.0 * unit.femtoseconds # set the timestep for integration
    >>> simulation.nsteps_per_iteration = 50 # run 50 timesteps per iteration
    >>> simulation.minimize = False # don't minimize first
    >>> # Run simulation.
    >>> simulation.run() # run the simulation

    """

    def create(self, system, positions, options=None, Tmin=None, Tmax=None, ntemps=None, temperatures=None, pressure=None, metadata=None):
        """
        Initialize a parallel tempering simulation object.

        Parameters
        ----------
        system : simtk.openmm.System
           the system to simulate
        positions : simtk.unit.Quantity of np natoms x 3 array of units length, or list
           coordinate set(s) for one or more replicas, assigned in a round-robin fashion
        Tmin : simtk.unit.Quantity with units compatible with kelvin, optional, default=None
           min temperature
        Tmax : simtk.unit.Quantity with units compatible with kelvin, optional, default=None
           max temperature
        ntemps : int, optional, default=None
           number of exponentially-spaced temperatures between Tmin and Tmax
        temperatures : list of simtk.unit.Quantity with units compatible with kelvin, optional, default=None
           if specified, this list of temperatures will be used instead of (Tmin, Tmax, ntemps)
        pressure : simtk.unit.Quantity with units compatible with atmospheres, optional, default=None
           if specified, a MonteCarloBarostat will be added (or modified) to perform NPT simulations
        options : dict, optional, default=None
           Options to use for specifying simulation protocol.  Provided keywords will be matched to object variables to replace defaults.

        Notes
        -----
        Either (Tmin, Tmax, ntempts) must all be specified or the list of 'temperatures' must be specified.

        """
        # Create thermodynamic states from temperatures.
        if temperatures is not None:
            logger.info("Using provided temperatures")
            self.temperatures = temperatures
        elif (Tmin is not None) and (Tmax is not None) and (ntemps is not None):
            self.temperatures = [ Tmin + (Tmax - Tmin) * (math.exp(float(i) / float(ntemps-1)) - 1.0) / (math.e - 1.0) for i in range(ntemps) ]
        else:
            raise ValueError("Either 'temperatures' or 'Tmin', 'Tmax', and 'ntemps' must be provided.")

        states = [ ThermodynamicState(system=system, temperature=self.temperatures[i], pressure=pressure) for i in range(ntemps) ]

        # Initialize replica-exchange simlulation.
        ReplicaExchange.create(self, states, positions, options=options, metadata=metadata)

        # Override title.
        self.title = 'Parallel tempering simulation created using ParallelTempering class of repex.py on %s' % time.asctime(time.localtime())

        return

    def _compute_energies(self):
        """
        Compute reduced potentials of all replicas at all states (temperatures).

        NOTES

        Because only the temperatures differ among replicas, we replace the generic O(N^2) replica-exchange implementation with an O(N) implementation.

        """

        start_time = time.time()
        logger.debug("Computing energies...")

        if self.mpicomm:
            # MPI implementation

            # Create an integrator and context.
            state = self.states[0]
            integrator = self.mm.VerletIntegrator(self.timestep)
            context = self._create_context(state.system, integrator)

            for replica_index in range(self.mpicomm.rank, self.nstates, self.mpicomm.size):
                # Set positions.
                context.setPositions(self.replica_positions[replica_index])
                # Compute potential energy.
                openmm_state = context.getState(getEnergy=True)
                potential_energy = openmm_state.getPotentialEnergy()
                # Compute energies at this state for all replicas.
                for state_index in range(self.nstates):
                    # Compute reduced potential
                    beta = 1.0 / (kB * self.states[state_index].temperature)
                    self.u_kl[replica_index,state_index] = beta * potential_energy

            # Gather energies.
            energies_gather = self.mpicomm.allgather(self.u_kl[self.mpicomm.rank:self.nstates:self.mpicomm.size,:])
            for replica_index in range(self.nstates):
                source = replica_index % self.mpicomm.size # node with trajectory data
                index = replica_index // self.mpicomm.size # index within trajectory batch
                self.u_kl[replica_index,:] = energies_gather[source][index]

            # Clean up.
            del context, integrator

        else:
            # Serial implementation.

            # Create an integrator and context.
            state = self.states[0]
            integrator = self.mm.VerletIntegrator(self.timestep)
            context = self._create_context(state.system, integrator)

            # Compute reduced potentials for all configurations in all states.
            for replica_index in range(self.nstates):
                # Set positions.
                context.setPositions(self.replica_positions[replica_index])
                # Compute potential energy.
                openmm_state = context.getState(getEnergy=True)
                potential_energy = openmm_state.getPotentialEnergy()
                # Compute energies at this state for all replicas.
                for state_index in range(self.nstates):
                    # Compute reduced potential
                    beta = 1.0 / (kB * self.states[state_index].temperature)
                    self.u_kl[replica_index,state_index] = beta * potential_energy

            # Clean up.
            del context, integrator

        end_time = time.time()
        elapsed_time = end_time - start_time
        time_per_energy = elapsed_time / float(self.nstates)
        logger.debug("Time to compute all energies %.3f s (%.3f per energy calculation).\n" % (elapsed_time, time_per_energy))

        return

#=============================================================================================
# Hamiltonian exchange
#=============================================================================================

class HamiltonianExchange(ReplicaExchange):
    """
    Hamiltonian exchange simulation facility.

    DESCRIPTION

    This class provides an implementation of a Hamiltonian exchange simulation based on the ReplicaExchange facility.
    It provides several convenience classes and efficiency improvements, and should be preferentially used for Hamiltonian
    exchange simulations over ReplicaExchange when possible.

    EXAMPLES

    >>> # Create baseline system
    >>> from openmmtools import testsystems
    >>> testsystem = testsystems.AlanineDipeptideImplicit()
    >>> [base_system, positions] = [testsystem.system, testsystem.positions]
    >>> # Copy baseline system.
    >>> systems = [base_system for index in range(10)]
    >>> # Create temporary file for storing output.
    >>> import tempfile
    >>> file = tempfile.NamedTemporaryFile() # temporary file for testing
    >>> store_filename = file.name
    >>> # Create baseline state.
    >>> base_state = ThermodynamicState(base_system, temperature=298.0*unit.kelvin)
    >>> # Create simulation.
    >>> simulation = HamiltonianExchange(store_filename)
    >>> simulation.create(base_state, systems, positions)
    >>> simulation.number_of_iterations = 2 # set the simulation to only run 2 iterations
    >>> simulation.timestep = 2.0 * unit.femtoseconds # set the timestep for integration
    >>> simulation.nsteps_per_iteration = 50 # run 50 timesteps per iteration
    >>> simulation.minimize = False
    >>> # Run simulation.
    >>> simulation.run() #doctest: +ELLIPSIS
    ...

    """

    def create(self, base_state, systems, positions, options=None, metadata=None):
        """
        Initialize a Hamiltonian exchange simulation object.

        Parameters
        ----------
        base_state : ThermodynamicState
           baseline state containing all thermodynamic parameters except the system, which will be replaced by 'systems'
        systems : list of simtk.openmm.System
           list of systems to simulate (one per replica)
        positions : simtk.unit.Quantity of np natoms x 3 with units compatible with nanometers
           positions (or a list of positions objects) for initial assignment of replicas (will be used in round-robin assignment)
        options : dict, optional, default=None
           Optional dict to use for specifying simulation protocol. Provided keywords will be matched to object variables to replace defaults.
        metadata : dict, optional, default=None
           metadata to store in a 'metadata' group in store file

        """

        if systems is None:
            states = None
        else:
            # Create thermodynamic states from systems.
            states = [ ThermodynamicState(system=system, temperature=base_state.temperature, pressure=base_state.pressure) for system in systems ]

        # Initialize replica-exchange simlulation.
        ReplicaExchange.create(self, states, positions, options=options, metadata=metadata)

        # Override title.
        self.title = 'Hamiltonian exchange simulation created using HamiltonianExchange class of repex.py on %s' % time.asctime(time.localtime())

        return

#=============================================================================================
# MAIN AND TESTS
#=============================================================================================

if __name__ == "__main__":
    import doctest
    doctest.testmod()
